import argparse
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

def merge_lora(base, lora, out):
    print("ðŸ”Œ Chargement du modÃ¨le de baseâ€¦")
    model = AutoModelForCausalLM.from_pretrained(base, torch_dtype=torch.float32)

    print("ðŸŽ¯ Application du LoRAâ€¦")
    model = PeftModel.from_pretrained(model, lora)

    print("ðŸ”§ Fusion des poids LoRA dans le modÃ¨leâ€¦")
    model = model.merge_and_unload()

    print(f"ðŸ’¾ Sauvegarde du modÃ¨le fusionnÃ© dans : {out}")
    model.save_pretrained(out)
    tokenizer = AutoTokenizer.from_pretrained(base)
    tokenizer.save_pretrained(out)

    print("âœ… Fusion terminÃ©e !")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--base_model")
    parser.add_argument("--lora_path")
    parser.add_argument("--output")
    args = parser.parse_args()

    merge_lora(args.base_model, args.lora_path, args.output)
